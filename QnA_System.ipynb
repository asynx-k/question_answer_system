{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9a57c2d3-238d-4601-b5f9-39326fd84a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# SKLEARN METRICS\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTORCH\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# HUGGING FACE\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "import evaluate\n",
    "\n",
    "# SPACY\n",
    "import spacy\n",
    "import spacy_dbpedia_spotlight\n",
    "\n",
    "# SPARQL\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# OLLAMA\n",
    "import ollama\n",
    "\n",
    "# TRANSITIONS\n",
    "from transitions import Machine\n",
    "\n",
    "# --------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d19622f-0f65-48b0-9621-8cb1bc1d47f4",
   "metadata": {},
   "source": [
    "# Dataset Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8cb179-7031-4bf9-8f02-78f0d933caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\"train\": \"train.json\", \"validation\": \"valid.json\", \"test\": \"test.json\"}\n",
    "dataset = load_dataset(path=\"data//\", data_files=data_files)\n",
    "\n",
    "train = pd.DataFrame(dataset['train']['Questions'])\n",
    "valid = pd.DataFrame(dataset['validation']['Questions'])\n",
    "test = pd.DataFrame(dataset['test']['Questions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2a59f8-0fb7-4ea3-acfd-5a9f524e94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(data):\n",
    "    data = data[data.PredicateList.str.len() == 1].reset_index()\n",
    "    data.PredicateList = data.PredicateList.str[0]\n",
    "    data['Constraint'] = data.PredicateList.str['Constraint']\n",
    "    data['Direction'] = data.PredicateList.str['Direction']\n",
    "    data['Predicate'] = data.PredicateList.str['Predicate']\n",
    "\n",
    "    return data[['Query', 'Direction', 'Subject', 'Predicate', 'Constraint']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6a8cbd4-fd65-4481-b3fe-3c1be3c9f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train = process_dataset(train)\n",
    "processed_valid = process_dataset(valid)\n",
    "processed_test = process_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f8a7be-8c95-4a21-a697-de4fdaa3acea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Predicate</th>\n",
       "      <th>Constraint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what movie is produced by warner bros.</td>\n",
       "      <td>backward</td>\n",
       "      <td>http://dbpedia.org/resource/Warner_Bros.</td>\n",
       "      <td>http://dbpedia.org/ontology/distributor</td>\n",
       "      <td>http://dbpedia.org/ontology/Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is don graham known as?</td>\n",
       "      <td>forward</td>\n",
       "      <td>http://dbpedia.org/resource/Don_Graham_(Americ...</td>\n",
       "      <td>http://purl.org/linguistics/gold/hypernym</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which city did the artist ryna originate in</td>\n",
       "      <td>forward</td>\n",
       "      <td>http://dbpedia.org/resource/RYNA</td>\n",
       "      <td>http://dbpedia.org/ontology/hometown</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who produced the film rough house rosie</td>\n",
       "      <td>forward</td>\n",
       "      <td>http://dbpedia.org/resource/Rough_House_Rosie</td>\n",
       "      <td>http://dbpedia.org/ontology/producer</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the language in which mera shikar was ...</td>\n",
       "      <td>forward</td>\n",
       "      <td>http://dbpedia.org/resource/Mera_Shikar</td>\n",
       "      <td>http://dbpedia.org/ontology/language</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query Direction  \\\n",
       "0             what movie is produced by warner bros.  backward   \n",
       "1                       What is don graham known as?   forward   \n",
       "2        Which city did the artist ryna originate in   forward   \n",
       "3            who produced the film rough house rosie   forward   \n",
       "4  what is the language in which mera shikar was ...   forward   \n",
       "\n",
       "                                             Subject  \\\n",
       "0           http://dbpedia.org/resource/Warner_Bros.   \n",
       "1  http://dbpedia.org/resource/Don_Graham_(Americ...   \n",
       "2                   http://dbpedia.org/resource/RYNA   \n",
       "3      http://dbpedia.org/resource/Rough_House_Rosie   \n",
       "4            http://dbpedia.org/resource/Mera_Shikar   \n",
       "\n",
       "                                   Predicate                        Constraint  \n",
       "0    http://dbpedia.org/ontology/distributor  http://dbpedia.org/ontology/Film  \n",
       "1  http://purl.org/linguistics/gold/hypernym                              None  \n",
       "2       http://dbpedia.org/ontology/hometown                              None  \n",
       "3       http://dbpedia.org/ontology/producer                              None  \n",
       "4       http://dbpedia.org/ontology/language                              None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "942ac172-9b2e-4d58-84f3-77cd5007fba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'which musician recorded metal blade records'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_question = processed_train.Query.sample(1).values[0]\n",
    "\n",
    "random_question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd8e3ad-fb92-4005-8130-26bb8c4b5cfa",
   "metadata": {},
   "source": [
    "# Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ead71773-3035-4a80-9e93-021b48411508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(question):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nlp.add_pipe(\"dbpedia_spotlight\", config={\"verify_ssl\": False})\n",
    "\n",
    "    doc = nlp(question)[-1]\n",
    "    entities = [(ent.text, ent.label_, ent.kb_id_) for ent in doc.ents]\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "954135af-0d8d-4a40-ac4e-443318d0430b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('metal blade records',\n",
       "  'DBPEDIA_ENT',\n",
       "  'http://dbpedia.org/resource/Metal_Blade_Records')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entities(random_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb5b8a2-9773-436b-9299-5387e4dbdd3e",
   "metadata": {},
   "source": [
    "# Predicate Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee396b4-a4f6-4e5c-b5a5-c9f494fa47ad",
   "metadata": {},
   "source": [
    "## Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a42f79-73e2-429f-b2c5-0fa54c0fc090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicates = processed_train.Predicate.unique()\n",
    "\n",
    "len(predicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbe58170-459b-4d01-ba4d-5cd9e0d474ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_id2label = {ind: predicate for ind, predicate in enumerate(predicates)}\n",
    "pred_label2id = {predicate: ind for ind, predicate in pred_id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d91b2852-a5aa-4154-ac42-673c5f74711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_train = processed_train[[\"Query\", \"Predicate\"]]\n",
    "predicate_train.Predicate = predicate_train.Predicate.map(pred_label2id)\n",
    "\n",
    "predicate_valid = processed_valid[[\"Query\", \"Predicate\"]]\n",
    "predicate_valid.Predicate = predicate_valid.Predicate.map(pred_label2id)\n",
    "\n",
    "predicate_test = processed_test[[\"Query\", \"Predicate\"]]\n",
    "predicate_test.Predicate = predicate_test.Predicate.map(pred_label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c07fa5f-63ef-478d-ba29-8035f6f348b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Predicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what movie is produced by warner bros.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is don graham known as?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which city did the artist ryna originate in</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who produced the film rough house rosie</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the language in which mera shikar was ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23811</th>\n",
       "      <td>What sort of music does tevin campbell perform</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>what kind of composition is twistin' the night...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23813</th>\n",
       "      <td>which artist composes video game music</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23814</th>\n",
       "      <td>What gender is gastón filgueira</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23815</th>\n",
       "      <td>name a insurance  company</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Query  Predicate\n",
       "0                 what movie is produced by warner bros.          0\n",
       "1                           What is don graham known as?          1\n",
       "2            Which city did the artist ryna originate in          2\n",
       "3                who produced the film rough house rosie          3\n",
       "4      what is the language in which mera shikar was ...          4\n",
       "...                                                  ...        ...\n",
       "23811     What sort of music does tevin campbell perform         10\n",
       "23812  what kind of composition is twistin' the night...          1\n",
       "23813             which artist composes video game music         10\n",
       "23814                    What gender is gastón filgueira         12\n",
       "23815                          name a insurance  company         27\n",
       "\n",
       "[23816 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicate_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "125d5e03-c647-4bca-9315-6fa0991433b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_train = Dataset.from_pandas(predicate_train)\n",
    "predicate_valid = Dataset.from_pandas(predicate_valid)\n",
    "predicate_test = Dataset.from_pandas(predicate_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a36abc2-6f1e-4458-8a28-b00bc4c30cf9",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be940c66-c4eb-49a5-b389-3033f32a3c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([100, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "predicate_classifier = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                                                          num_labels=len(pred_label2id),\n",
    "                                                                          id2label=pred_id2label, label2id=pred_label2id,\n",
    "                                                                          ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df56dfeb-0f0b-46a2-b6aa-97fb180d1399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"Query\"], padding=\"max_length\", truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "331b9dbc-7e0e-41e1-8553-2f15a00893fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f2859d3cba452e96a3bf700a8edbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23816 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f99d6cdbc9b4a1ca717264d73023b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3407 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1a93ac91334fb2b25360d1fe499e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdace93722b4c0a88005321bc29e270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23816 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb3300295874aadb2533eb02c4c9693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23816 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542f6719f29947408cc0b4f25a396001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train = predicate_train.map(tokenize, batched=True)\n",
    "tokenized_valid = predicate_valid.map(tokenize, batched=True)\n",
    "tokenized_test = predicate_test.map(tokenize, batched=True)\n",
    "\n",
    "tokenized_train = tokenized_train.map(lambda x: {\"labels\": x[\"Predicate\"]}, batched=True)\n",
    "tokenized_valid = tokenized_train.map(lambda x: {\"labels\": x[\"Predicate\"]}, batched=True)\n",
    "tokenized_test = tokenized_test.map(lambda x: {\"labels\": x[\"Predicate\"]}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf1c8d64-42ae-4458-b5a0-9e2adf6fdf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bcba758-d3a5-4d24-bb5c-22b53aef53d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2980' max='2980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2980/2980 26:01, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.501000</td>\n",
       "      <td>0.403231</td>\n",
       "      <td>0.909767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.466800</td>\n",
       "      <td>0.249886</td>\n",
       "      <td>0.939998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.192463</td>\n",
       "      <td>0.950663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.166421</td>\n",
       "      <td>0.957340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2980, training_loss=0.500971695560737, metrics={'train_runtime': 1562.5847, 'train_samples_per_second': 60.966, 'train_steps_per_second': 1.907, 'total_flos': 1.264142903083008e+16, 'train_loss': 0.500971695560737, 'epoch': 4.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./predicate_classifier\",\n",
    "    learning_rate=3e-5,\n",
    "    eval_strategy='epoch',\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    fp16=True,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=predicate_classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89e5944f-cfbb-45a1-b30d-faa5347b5b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./predicate_classifier/tokenizer\\\\tokenizer_config.json',\n",
       " './predicate_classifier/tokenizer\\\\special_tokens_map.json',\n",
       " './predicate_classifier/tokenizer\\\\vocab.txt',\n",
       " './predicate_classifier/tokenizer\\\\added_tokens.json',\n",
       " './predicate_classifier/tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicate_classifier.save_pretrained(\"./predicate_classifier/model\")\n",
    "tokenizer.save_pretrained(\"./predicate_classifier/tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f4b923-1e2c-4ee9-ade7-e83c40394ff0",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76e4522f-8913-4117-85f3-90e7f439951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicate(question):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./predicate_classifier/tokenizer\")\n",
    "    predicate_classifier = AutoModelForSequenceClassification.from_pretrained(\"./predicate_classifier/model\").cpu()\n",
    "\n",
    "    predicate_classifier.eval()\n",
    "\n",
    "    tokenized_q = tokenizer(question, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        logits = predicate_classifier(**tokenized_q).logits.softmax(-1)\n",
    "        pred = logits.argmax(-1).item()\n",
    "        confidence = logits.max(-1).values.item()\n",
    "        predicate = predicate_classifier.config.id2label[pred]\n",
    "\n",
    "    return predicate, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b36a0ee9-7fb8-4f0c-9c5e-bf55615b205b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://dbpedia.org/ontology/recordLabel', 0.9973101615905762)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicate(random_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3315a1-7f5d-4f32-b388-12d8afdecfd8",
   "metadata": {},
   "source": [
    "# Question Direction Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23796a3-dc8d-4ad6-92b0-b53c72db8abd",
   "metadata": {},
   "source": [
    "## Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa0866e4-fe12-43e4-968a-9257ea9e00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./predicate_classifier/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "24713940-5737-4f58-8d56-0c40bbdbec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_id2label = {0: 'forward', 1: 'backward'}\n",
    "type_label2id = {'forward': 0, 'backward': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2eb5bd7-8841-4360-9598-802209074c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_train = processed_train[['Query', 'Direction']]\n",
    "type_valid = processed_valid[['Query', 'Direction']]\n",
    "type_test = processed_valid[['Query', 'Direction']]\n",
    "\n",
    "type_train.Direction = type_train.Direction.map(type_label2id)\n",
    "type_valid.Direction = type_valid.Direction.map(type_label2id)\n",
    "type_test.Direction = type_test.Direction.map(type_label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f2501ea-b3ac-40ec-a6e0-6ed9b239d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryTypeDataset():\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        q, t = self.data.iloc[idx]\n",
    "        tokenized = tokenizer(q, padding=\"max_length\", truncation=True, return_tensors=\"pt\")['input_ids'].squeeze(0)\n",
    "        \n",
    "        return tokenized, t\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "06fa907d-e920-455d-9b2a-6f40bc186a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_type_dataset = QueryTypeDataset(type_train, tokenizer)\n",
    "valid_type_dataset = QueryTypeDataset(type_valid, tokenizer)\n",
    "test_type_dataset = QueryTypeDataset(type_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e619ba9-089f-4855-9b57-2c96a19465d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_type_dataset, batch_size=16)\n",
    "valid_dataloader = DataLoader(valid_type_dataset, batch_size=16)\n",
    "test_type_dataset = DataLoader(test_type_dataset, batch_size=len(test_type_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68303bd-7861-48ad-93e2-6a60f1fbf729",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e22c295d-5d49-4665-8ccf-4232bc192054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "685527c3-3495-4eae-853a-2c3969db994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=30522, embed_dim=32, hidden_size=16, n_classes=2, id2label=type_id2label, label2id=type_label2id):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, \n",
    "                                      embedding_dim=embed_dim, \n",
    "                                      padding_idx=0)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2*hidden_size, n_classes)\n",
    "\n",
    "        self.id2label = id2label\n",
    "        self.label2id = label2id\n",
    "\n",
    "    def forward(self, X):\n",
    "        emb = self.embedding(X)\n",
    "        out, h = self.gru(emb)\n",
    "    \n",
    "        h = torch.cat((h[0], h[1]), axis=1)\n",
    "        pred = self.fc(h)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a7b3e045-da3b-439c-b177-bcc426779f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, dataloader, loss, optimizer, verbose=False):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "\n",
    "    for idx, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        predict_logits = model(X)\n",
    "        batch_loss = loss(predict_logits, y.flatten())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += batch_loss.item()\n",
    "\n",
    "        ground_truth.extend(y.flatten().tolist())\n",
    "        predictions.extend(predict_logits.argmax(-1).tolist())\n",
    "\n",
    "        if verbose and idx % verbose == 0:\n",
    "            print(f'Loss: {round(batch_loss.item(), 5)}')\n",
    "\n",
    "    epoch_loss /= len(dataloader)\n",
    "    accuracy = accuracy_score(ground_truth, predictions)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Train Loss: {round(epoch_loss, 5)}\\t Train Accuracy: {round(accuracy, 5)*100}%')\n",
    "\n",
    "    return epoch_loss, accuracy, ground_truth, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8660f960-429e-4773-a46e-639a3c26f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, dataloader, loss, verbose=False):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    ground_truth = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "    \n",
    "            predict_logits = model(X)\n",
    "            batch_loss = loss(predict_logits, y.flatten())\n",
    "\n",
    "            epoch_loss += batch_loss.item()\n",
    "\n",
    "            ground_truth.extend(y.flatten().tolist())\n",
    "            predictions.extend(predict_logits.argmax(-1).tolist())\n",
    "    \n",
    "        epoch_loss /= len(dataloader)\n",
    "        accuracy = accuracy_score(ground_truth, predictions)\n",
    "    \n",
    "        if verbose:\n",
    "            print(f'Test Loss: {round(epoch_loss, 5)}\\t Test Accuracy: {round(accuracy, 5)*100}%\\n')\n",
    "    \n",
    "        return epoch_loss, accuracy, ground_truth, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d829735f-0ca5-46f7-b108-55c5d922ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_classifier = TypeClassifier(vocab_size=tokenizer.vocab_size,\n",
    "                                 embed_dim=32,\n",
    "                                 hidden_size=16,\n",
    "                                 n_classes=2, \n",
    "                                 id2label=type_id2label, label2id=type_label2id).to(DEVICE)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(type_classifier.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "n_epoch = 3\n",
    "print_every = 1\n",
    "verbose_every = 500\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d6fb207a-9712-4d7f-8f7f-a302324d0d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "---------------\n",
      "Loss: 0.70427\n",
      "Loss: 0.49073\n",
      "Loss: 0.27611\n",
      "Train Loss: 0.21841\t Train Accuracy: 91.455%\n",
      "Test Loss: 0.13994\t Test Accuracy: 95.216%\n",
      "\n",
      "EPOCH 1\n",
      "---------------\n",
      "Loss: 0.16254\n",
      "Loss: 0.36628\n",
      "Loss: 0.23328\n",
      "Train Loss: 0.10459\t Train Accuracy: 96.536%\n",
      "Test Loss: 0.11281\t Test Accuracy: 96.00800000000001%\n",
      "\n",
      "EPOCH 2\n",
      "---------------\n",
      "Loss: 0.0798\n",
      "Loss: 0.16803\n",
      "Loss: 0.19163\n",
      "Train Loss: 0.07437\t Train Accuracy: 97.733%\n",
      "Test Loss: 0.09662\t Test Accuracy: 96.74199999999999%\n",
      "\n",
      "EPOCH 3\n",
      "---------------\n",
      "Loss: 0.03317\n",
      "Loss: 0.06721\n",
      "Loss: 0.16672\n",
      "Train Loss: 0.05392\t Train Accuracy: 98.455%\n",
      "Test Loss: 0.09287\t Test Accuracy: 97.182%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch + 1):\n",
    "    if epoch % print_every == 0:\n",
    "        print(f'EPOCH {epoch}\\n---------------')\n",
    "        verbose = verbose_every\n",
    "    else:\n",
    "        verbose = False\n",
    "\n",
    "    train_res = train_loop(type_classifier, train_dataloader, loss, optimizer, verbose)\n",
    "    test_res = test_loop(type_classifier, valid_dataloader, loss, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "91fcc78d-fd1a-41a5-8149-2ce7b76714cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(type_classifier.state_dict(), \"./type_classifier/type_classifer.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3835d3-d343-48fb-9769-c9489f188f07",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "48fdb810-4e9c-481d-9da3-f49ecbace0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction(question):\n",
    "    type_classifier = TypeClassifier(vocab_size=tokenizer.vocab_size,\n",
    "                                 embed_dim=32,\n",
    "                                 hidden_size=16,\n",
    "                                 n_classes=2, \n",
    "                                 id2label=type_id2label, label2id=type_label2id).cpu()\n",
    "    type_classifier.load_state_dict(torch.load(\"./type_classifier/type_classifer.pth\", weights_only=True))\n",
    "    type_classifier.eval()\n",
    "\n",
    "    tokenized_q = tokenizer(question, padding=\"max_length\", truncation=True, return_tensors='pt')['input_ids']\n",
    "    with torch.no_grad():\n",
    "        logits = type_classifier(tokenized_q).softmax(-1)\n",
    "        pred = logits.argmax(-1).item()\n",
    "        confidence = logits.max(-1).values.item()\n",
    "        predicate = type_classifier.id2label[pred]\n",
    "\n",
    "    return predicate, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e6bdf45d-b361-4888-b147-ececa8e51a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('backward', 0.9966727495193481)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_direction(random_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c3aff7-a7f0-4398-b200-d2c2ae6e480b",
   "metadata": {},
   "source": [
    "# Building a QnA system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b4f1a9ff-6a6e-4a36-87e8-d3534e66b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QnAAgent():\n",
    "    states = ['start',\n",
    "              'ner_success', 'ner_fail',\n",
    "              'predicate_success', 'predicate_fail',\n",
    "              'type_success', 'type_fail',\n",
    "              'query_success', 'query_fail']\n",
    "    \n",
    "    def __init__(self):\n",
    "        # NER\n",
    "        self.ner_model = spacy.load(\"en_core_web_sm\")\n",
    "        self.ner_model.add_pipe(\"dbpedia_spotlight\", config={\"verify_ssl\": False})\n",
    "\n",
    "        # PREDICATE\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"./predicate_classifier/tokenizer\")\n",
    "        self.predicate_classifier = AutoModelForSequenceClassification.from_pretrained(\"./predicate_classifier/model\").cpu()\n",
    "        self.predicate_classifier.eval()\n",
    "\n",
    "        # DIRECTION TYPE\n",
    "        self.type_classifier = TypeClassifier()\n",
    "        self.type_classifier.load_state_dict(torch.load(\"./type_classifier/type_classifer.pth\", weights_only=True))\n",
    "        self.type_classifier.eval()\n",
    "\n",
    "        # QUERY TEMPLATES\n",
    "        self.query_templates = {'backward':'SELECT DISTINCT ?subj WHERE {{?subj <{predicate}> <{entity}>}}',\n",
    "                                'forward':'SELECT DISTINCT ?obj WHERE {{<{entity}> <{predicate}> ?obj}}'}\n",
    "\n",
    "        # SPARQL AND LLM\n",
    "        self.sparql = SPARQLWrapper(\"https://dbpedia.org/sparql\")\n",
    "        self.llm = ollama\n",
    "\n",
    "        self.entity = None\n",
    "        self.predicate = None\n",
    "        self.type = None\n",
    "        self.answer = None\n",
    "\n",
    "        # TRANSITIONS\n",
    "        self.machine = Machine(model=self, states=QnAAgent.states, send_event=True, initial='start')\n",
    "\n",
    "        self.machine.add_transition(trigger='proceed', source='start', \n",
    "                                    prepare='get_entity', \n",
    "                                    dest='ner_success', conditions='is_ner_success')\n",
    "        self.machine.add_transition(trigger='proceed', source='start', \n",
    "                                    prepare='get_entity', \n",
    "                                    dest='ner_fail', unless='is_ner_success', \n",
    "                                    after='end')\n",
    "        \n",
    "        self.machine.add_transition(trigger='proceed', source='ner_success', \n",
    "                                    prepare='get_predicate', \n",
    "                                    dest='predicate_success', conditions='is_predicate_success')\n",
    "        self.machine.add_transition(trigger='proceed', source='ner_success', \n",
    "                                    prepare='get_predicate', \n",
    "                                    dest='predicate_fail', unless='is_predicate_success', \n",
    "                                    after='end')\n",
    "        \n",
    "        self.machine.add_transition(trigger='proceed', source='predicate_success', \n",
    "                                    prepare='get_type', \n",
    "                                    dest='type_success', conditions='is_type_success')\n",
    "        self.machine.add_transition(trigger='proceed', source='predicate_success', \n",
    "                                    prepare='get_type', \n",
    "                                    dest='type_fail', unless='is_type_success', \n",
    "                                    after='end')\n",
    "\n",
    "        self.machine.add_transition(trigger='proceed', source='type_success', \n",
    "                                    prepare='get_answer', \n",
    "                                    dest='query_success', conditions='is_query_success', after='respond')\n",
    "        self.machine.add_transition(trigger='proceed', source='type_success', \n",
    "                                    prepare='get_answer', \n",
    "                                    dest='query_fail', unless='is_query_success', after='end')\n",
    "        \n",
    "        self.machine.add_transition(trigger='reset', source='*', prepare=['empty'], dest='start')\n",
    "\n",
    "    # CHECKS\n",
    "    def is_ner_success(self, event):\n",
    "        return self.entity is not None\n",
    "\n",
    "    def is_predicate_success(self, event):\n",
    "        return self.predicate[0] is not None and self.predicate[1] >= 0.7\n",
    "\n",
    "    def is_type_success(self, event):\n",
    "        return self.type[0] is not None and self.type[1] >= 0.7\n",
    "\n",
    "    def is_query_success(self, event):\n",
    "        return self.answer is not None\n",
    "\n",
    "    def end(self, event):\n",
    "        print('Failed to find an answer. Please, paraphrase your question.')\n",
    "\n",
    "    # QUESTION PROCESSING\n",
    "    def get_entity(self, event):\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        nlp.add_pipe(\"dbpedia_spotlight\", config={\"verify_ssl\": False})\n",
    "    \n",
    "        doc = self.ner_model(event.kwargs.get('question'))\n",
    "        if not doc.ents:\n",
    "            self.entity = None\n",
    "        else:\n",
    "            self.entity = doc.ents[-1].kb_id_\n",
    "\n",
    "    def get_predicate(self, event):\n",
    "        tokenized_q = self.tokenizer(event.kwargs.get('question'), padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = self.predicate_classifier(**tokenized_q).logits.softmax(-1)\n",
    "            pred = logits.argmax(-1).item()\n",
    "            \n",
    "            confidence = logits.max(-1).values.item()\n",
    "            predicate = self.predicate_classifier.config.id2label[pred]\n",
    "\n",
    "        self.predicate = (predicate, confidence)\n",
    "\n",
    "    def get_type(self, event):\n",
    "        tokenized_q = self.tokenizer(event.kwargs.get('question'), padding=\"max_length\", truncation=True, return_tensors='pt')['input_ids']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = self.type_classifier(tokenized_q).softmax(-1)\n",
    "            pred = logits.argmax(-1).item()\n",
    "            \n",
    "            confidence = logits.max(-1).values.item()\n",
    "            predicate = self.type_classifier.id2label[pred]\n",
    "\n",
    "        self.type = (predicate, confidence)\n",
    "    \n",
    "    def get_answer(self, event):\n",
    "        query = self.query_templates[self.type[0]].format(predicate=self.predicate[0], entity=self.entity)\n",
    "        \n",
    "        self.sparql.setQuery(query)\n",
    "        self.sparql.setReturnFormat(JSON)\n",
    "        \n",
    "        results = self.sparql.query().convert()\n",
    "        if not results['results']['bindings']:\n",
    "            self.answer = None\n",
    "        else:\n",
    "            answer_data = results['results']['bindings']\n",
    "            answer_data = list(map(lambda a: list(a.values())[0]['value'], answer_data))\n",
    "            answer_data = list(map(lambda a: a[a.rfind('/')+1:], answer_data))\n",
    "    \n",
    "            self.answer = answer_data\n",
    "    \n",
    "    # CHATBOT FUNCTIONALITY\n",
    "    def empty(self, event):\n",
    "        self.entity = None\n",
    "        self.predicate = None\n",
    "        self.type = None\n",
    "        self.answer = None\n",
    "\n",
    "    def respond(self, event):\n",
    "        print(f'Responding')\n",
    "        prompt = f\"\"\"\n",
    "        Answer concisely using ONLY these facts. \n",
    "        Talk as if you were asked this question directly and you just use the facts in this propt as if you know them yourself.\n",
    "        Question: {event.kwargs.get('question')}\n",
    "        Facts: {self.answer[:10]}\n",
    "        Answer: \"\"\"\n",
    "        response = ollama.generate(model=\"mistral\", \n",
    "                                   prompt=prompt)\n",
    "        print(response[\"response\"].strip())\n",
    "\n",
    "        return self.answer\n",
    "\n",
    "    def ask(self, question):\n",
    "        while self.state not in ['ner_fail', 'predicate_fail', 'type_fail', 'query_fail', 'query_success']:\n",
    "            self.proceed(question=question)\n",
    "        print(f'Question info: {self.entity, self.predicate, self.type}')\n",
    "        self.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9567f71d-1b93-4240-a454-c71d40ca6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = QnAAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f00ee107-a8f1-4dc6-b232-4c986c5da55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 - what kind of music does stock aitken waterman play\n",
      "Responding\n",
      "Stock Aitken Waterman primarily produce Dance-pop, Eurobeat, Hi-NRG, and Pop music.\n",
      "Question info: ('http://dbpedia.org/resource/Stock_Aitken_Waterman', ('http://dbpedia.org/ontology/genre', 0.9990726709365845), ('forward', 0.9995988011360168))\n",
      "\n",
      "\n",
      "Q2 - which city was tommy neilson born in\n",
      "Responding\n",
      "Tommy Neilson was born in Gorebridge.\n",
      "Question info: ('http://dbpedia.org/resource/Tommy_Neilson', ('http://dbpedia.org/ontology/birthPlace', 0.9774978756904602), ('forward', 0.9987467527389526))\n",
      "\n",
      "\n",
      "Q3 - which animated film did jerry rees directed?\n",
      "Responding\n",
      "Jerry Rees directed \"The Brave Little Toaster.\"\n",
      "Question info: ('http://dbpedia.org/resource/Jerry_Rees', ('http://dbpedia.org/ontology/director', 0.9869979619979858), ('backward', 0.9947677850723267))\n",
      "\n",
      "\n",
      "Q4 - which fictional character was created by dan aykroyd\n",
      "Failed to find an answer. Please, paraphrase your question.\n",
      "Question info: ('http://dbpedia.org/resource/Dan_(rank)', ('http://dbpedia.org/ontology/creator', 0.9798502922058105), ('backward', 0.9918571710586548))\n",
      "\n",
      "\n",
      "Q5 - What type of musical style does beverley mitchell play?\n",
      "Failed to find an answer. Please, paraphrase your question.\n",
      "Question info: ('http://dbpedia.org/resource/Beverley_Mitchell', ('http://dbpedia.org/ontology/genre', 0.9981512427330017), ('forward', 0.9995691180229187))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = processed_train.Query.sample(5).values\n",
    "\n",
    "for ind, q in enumerate(questions):\n",
    "    print(f'Q{ind + 1} - {q}')\n",
    "    agent.ask(q)\n",
    "    print(f'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e80a48-010c-4846-8635-f7bb6ebd1211",
   "metadata": {},
   "source": [
    "Some entites appear to have no relevant information to answer the question, which is the primary reason for failures to find an answer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
